name: Terraform Apply

on:
  #   push:
  #     branches: [main]
  workflow_dispatch: # allows manual trigger
    inputs:
      region:
        description: "AWS region to deploy to"
        required: true
        default: "ap-southeast-2"
      deployS3:
        description: "Deploy S3 bucket?"
        required: true
        default: "false"
      deployGlueTables:
        description: "Deploy tables in Glue Catalog?"
        required: true
        default: "false"
      deployEC2:
        description: "Deploy VPC and EC2 instance?"
        required: true
        default: "false"
      deployDMS:
        description: "Deploy DMS instance, endpoints, and tasks?"
        required: true
        default: "false"
      deployEMR:
        description: "Deploy EMR resources?"
        required: true
        default: "false"
      deployMWAA:
        description: "Deploy MWAA dag?"
        required: true
        default: "false"

jobs:
  terraform:
    name: Run Terraform
    runs-on: ubuntu-latest

    defaults:
      run:
        working-directory: environments/dev

    env:
      TF_VERSION: 1.6.0

    steps:
      - name: Configure AWS credentials
        id: creds
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ github.event.inputs.region }}

      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: ${{ env.TF_VERSION }}

      # - name: Install boto3 for external data script
      #   run: pip3 install boto3

      - name: Terraform Init
        run: terraform init

      - name: Terraform Format Check
        run: terraform fmt -check

      - name: Terraform validate
        run: terraform validate

      - name: Terraform Plan
        run: terraform plan

      - name: Terraform Apply S3
        if: ${{ github.event.inputs.deployS3 == 'true' && github.ref == 'refs/heads/main'}} # apply only on main
        run: terraform apply -auto-approve -target=module.s3

      - name: Terraform Apply Glue Databases and Tables
        if: ${{ github.event.inputs.deployGlueTables == 'true' && github.ref == 'refs/heads/main'}}
        run: terraform apply -auto-approve -target=module.glue_catalog_table

      - name: Terraform Apply VPC, EC2
        if: ${{ github.event.inputs.deployEC2 == 'true' && github.ref == 'refs/heads/main'}}
        run: terraform apply -auto-approve -target=module.vpc -target=module.ec2

      - name: Terraform Apply DMS
        if: ${{ github.event.inputs.deployDMS == 'true' && github.ref == 'refs/heads/main'}}
        run: terraform apply -auto-approve -target=module.dms

      - name: Extract source bucket from tfvars
        id: extract-vars
        run: |
          SOURCE_BUCKET=$(grep 'source_bucket' ./terraform.tfvars | cut -d '=' -f2 | tr -d ' "')
          echo "SOURCE_BUCKET=$SOURCE_BUCKET" >> $GITHUB_ENV

      # - name: Compute hash and rename script
      #   run: |
      #     HASH=$(sha256sum scripts/bronze_to_silver.py | awk '{print $1}')
      #     cp ./scripts/pyspark/bronze_to_silver.py ./scripts/pyspark/scripts/bronze_to_silver_$HASH.py
      #     echo "SCRIPT_HASH=$HASH" >> $GITHUB_ENV

      - name: Upload pyspark script to S3
        if: ${{ github.event.inputs.deployEMR == 'true' }}
        run: |
          aws s3 cp ./../../scripts/pyspark/bronze_to_silver.py s3://$SOURCE_BUCKET/scripts/pyspark/
          # aws s3 cp ./scripts/pyspark/bronze_to_silver_$HASH.py s3://$SOURCE_BUCKET/scripts/pyapark/

      # upload script to S3 and deploy EMR script
      - name: Terraform Apply EMR
        if: ${{ github.event.inputs.deployEMR == 'true' && github.ref == 'refs/heads/main'}}
        run: |
          terraform apply -auto-approve -target=module.emr

      - name: Upload dag script to S3
        if: ${{ github.event.inputs.deployMWAA == 'true' }}
        run: |
          aws s3 cp ./../../scripts/dag/dms_to_emr_pipeline.py s3://$SOURCE_BUCKET/scripts/dag/
